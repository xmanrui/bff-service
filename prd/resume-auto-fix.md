# AI 驱动的 CI/CD 自愈系统 — 简历写法参考

## 项目名称

> **AI 驱动的 CI/CD 全链路自愈系统**

## STAR 写法示例

### 背景

团队微服务部署到 Kubernetes 集群后，故障排查链路长且分散：GitHub Actions 构建日志在 CI 平台，运行时错误在集群 Pod 日志和 Events 中，需要人工逐层排查、切换工具、定位根因、修复代码、重新部署，故障恢复效率低。

### 方案

设计并实现了基于 LLM 的 CI/CD 全链路闭环自愈系统，覆盖从 CI 构建到集群运行的完整故障面：

- 通过 GitHub Actions Workflow 实现容器镜像构建、推送至阿里云 ACR，并通过 Helm Chart 部署到 ACK 集群
- 构建了**三场景故障检测机制**：
  - **构建失败**：通过 `gh run view --json jobs` 精准判断失败阶段，自动拉取 CI 失败日志
  - **部署失败**：同时采集 CI 日志和 ACK 集群诊断信息，双源合并分析根因
  - **运行时异常**：CI 成功后通过 kubectl 探测 Pod 健康状态，并引入**二次稳定性检查**防止启动后立即崩溃的误判
- Pod 异常时自动采集 **7 维诊断信息**：Pod 状态概览、Pod Events、容器当前日志、上次崩溃日志（`--previous`）、Helm Values、Helm Manifest、集群 Events
- 实现了**智能日志截取算法**：通过错误关键字（Error、Exception、Traceback、OOMKilled 等）定位关键错误位置，截取关键字前 20 行 + 后 100 行上下文，找不到关键字时退化为取最后固定行数，在日志精度和 LLM 上下文长度之间取得平衡
- 设计了**三种场景专用 Prompt**（build / deploy / runtime），根据故障层级自动切换分析策略，收窄 LLM 分析范围
- 将故障日志 + 项目代码上下文注入 LLM Agent，由其自动完成根因分析、代码修复、git 提交推送
- 推送触发新一轮 CI/CD 流水线，形成 **"三场景检测 → 多维诊断 → 智能截取 → 根因分析 → 代码修复 → 重新部署"** 的自动闭环
- 设置最大重试轮次兜底机制，超限后输出修复摘要供人工介入

### 亮点

- **三场景精准检测**：区分构建失败 / 部署失败 / 运行时异常三种场景，构建失败只查 CI 日志，部署失败双源合并（CI + 集群），运行时异常只查集群，避免无效信息干扰 LLM 判断
- **7 维集群诊断**：自动采集 Pod Status / Events / 容器日志 / 崩溃日志 / Helm Values / Helm Manifest / 集群 Events，其中 Helm Values 和 Manifest 能直接暴露配置值错误（如镜像地址、数据库连接、资源限制等配置偏差）
- **智能日志截取**：基于错误关键字定位截取，解决了固定 tail 截断导致关键报错信息丢失的问题；同时限制每个 Pod 最多 120 行、最多采集 3 个 Pod 实例，控制总日志量不超出 LLM 上下文
- **三种专用 Prompt**：按故障层级设计差异化 Prompt，模拟有经验的 SRE 排查思路——先定位故障层，再在对应层内深入分析，避免统一 Prompt 导致分析方向发散
- **二次稳定性检查**：Pod 首次检查通过后间隔 30 秒再次检查，解决了应用启动后短暂存活随即崩溃的误判问题
- **双模式交付**：以 **Claude Code Skill**（交互式，可观察干预）和 **Shell 脚本**（非交互式，适合无人值守）两种形式交付，适配不同使用场景
- **成本优势**：单轮修复约 ¥1.5-7，约为人工排查成本的 1/10 到 1/50

## 技术栈关键词

```
LLM / AI Agent / Claude Code / Claude Code Skill / Prompt Engineering
GitHub Actions / CI/CD / Helm / Kubernetes / kubectl / 阿里云 ACK / ACR
FastAPI / Python / Docker / Shell
自动化 / 闭环 / 自愈 / 故障诊断 / 智能日志截取
```

## 面试准备建议

1. **突出系统设计而非工具调用**——你设计的是一个三场景检测 + 多维诊断 + 智能截取的闭环自愈架构，LLM 只是分析引擎，核心竞争力在于故障检测和诊断信息采集的工程设计
2. **用"三场景"讲故事**——举一个实际例子："CI 部署阶段 helm --wait 超时了，CI 日志只看到 timed out，但我的系统同时采集了集群 Pod 日志，发现是应用启动时连接数据库超时导致探针失败，LLM 综合两部分信息定位到 Helm values 中数据库地址配错并自动修复"
3. **准备现场 demo**——演示三个场景：① 构建失败自动修复 ② 部署失败双源诊断修复 ③ CI 成功但 Pod 崩溃自动修复
4. **准备高频追问**：
   - "LLM 修复错了怎么办？" → 最大重试次数兜底 + 每轮独立分析 + 交互式 Skill 模式可人工干预
   - "为什么不直接在 GitHub Actions 里调 LLM？" → 本地执行可以访问完整项目上下文 + kubectl 集群权限
   - "日志太多超出上下文怎么办？" → 智能截取（错误关键字前 20 行 + 后 100 行）+ Pod 实例上限 3 个 + 总行数封顶
   - "为什么要 3 种 Prompt？" → 不同场景错误类型不同，分场景收窄分析范围，模拟 SRE 排查思路
   - "成本如何？" → 单轮约 ¥1.5-7，约为人工排查的 1/10 到 1/50
   - "Skill 和脚本两种模式的取舍？" → Skill 适合开发阶段可观察可干预，脚本适合无人值守场景
