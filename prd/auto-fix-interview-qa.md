# Auto-Fix 面试高频问题及参考回答

## 一、系统设计类

### Q1: 为什么不直接在 GitHub Actions 里调 LLM 修复，要绕回本地？

GitHub Actions 运行环境是临时容器，workflow 结束就销毁了。在 CI 里调 LLM 有三个问题：
1. LLM 修复代码需要完整的项目上下文（读文件、跨文件分析），CI 环境虽然有代码但没有交互式分析能力
2. 部署阶段失败时需要用 kubectl 访问 ACK 集群拉日志，CI 环境的集群权限是受限的临时凭证，而本地有长期的 kubeconfig
3. 本地执行可以用 Claude Code Skill 的交互模式，开发者能实时观察分析过程并随时干预，CI 里只能黑盒运行

### Q2: 为什么要双层检测？一层不够吗？

不够。CI 成功只代表 `helm upgrade --install` 命令执行成功了，K8s 接受了这个部署请求，但 Pod 可能根本跑不起来。实际生产中大量故障发生在运行时：CrashLoopBackOff、OOMKilled、探针失败、环境变量缺失等，这些在 CI 视角全是 success。不加第二层检测，这类故障就成了盲区。

### Q3: 为什么部署阶段失败要同时看 CI 日志和集群日志？

因为部署阶段的根因分布在两个地方。比如 `helm upgrade --wait --timeout 300s` 超时了，CI 日志只能看到 "timed out waiting for the condition"，但超时的原因是什么——是 Pod CrashLoopBackOff、探针失败、还是镜像拉取失败——这些信息只在集群的 Pod Events 和容器日志里。只看 CI 日志会导致 LLM 无法定位根因，只看集群日志又可能遗漏 Helm 模板渲染错误这类 CI 层面的问题。

### Q4: 二次稳定性检查解决什么问题？

解决"假健康"问题。有些应用启动后能正常运行几秒甚至几十秒，之后因为内存泄漏触发 OOMKilled，或者首次请求触发未捕获异常而崩溃。如果只检查一次，恰好在存活的那几秒查到了 Running 状态，就会误判为部署成功。间隔 30 秒再查一次，能捕获这种启动即崩溃的场景。

---

## 二、LLM / AI 相关

### Q5: LLM 修复错了怎么办？

有三层防护：
1. **重试上限**：最多 3 轮，防止无限循环消耗资源和 API 额度
2. **每轮独立分析**：每轮都重新拉取最新日志分析，不沿用上一轮的假设，所以第一轮修错了第二轮有机会纠正
3. **交互模式兜底**：Skill 模式下开发者能看到 Claude 的分析过程和修改内容，发现方向不对可以随时干预。超过 3 轮还没修好，输出所有尝试的摘要，由人工接手

另外这个系统定位是开发/测试环境的效率工具，不是生产环境的自动运维。生产环境应该走正规的发布流程和审批。

### Q6: Prompt 是怎么设计的？为什么要分三种？

不同场景的错误类型完全不同，用统一的 prompt 会导致 LLM 分析方向发散。分三种 prompt 的目的是**收窄分析范围**：
- **build prompt**：引导关注 Dockerfile、依赖、ACR 认证，不提集群相关内容
- **deploy prompt**：明确告知有两部分信息，引导综合分析，列举 Helm 模板、探针超时等典型场景
- **runtime prompt**：明确告知 CI 成功，引导关注运行时问题，列举 OOMKilled、环境变量缺失等场景

本质上是用 prompt 模拟了一个有经验的 SRE 的排查思路——先定位故障层，再在对应层内深入分析。

### Q7: 6 维诊断信息为什么要这么多？能不能只看 Pod 日志？

不行，不同故障的根因分布在不同维度：

| 故障 | 根因所在维度 |
|---|---|
| 代码运行时报错 | 容器日志 (`kubectl logs`) |
| 启动后立刻崩溃 | 上次崩溃日志 (`kubectl logs --previous`) |
| OOMKilled | Pod Events (`kubectl describe pod`) |
| 镜像拉取失败 | 集群 Events (`kubectl get events`) |
| 节点资源不足调度失败 | Pod 描述 (`kubectl describe pod`) |
| Helm values 配置错误 | Helm 状态 (`helm status`) |

只看容器日志能覆盖的故障不到一半。6 维信息是为了让 LLM 有足够的上下文做准确判断，减少因信息不全导致的误诊。

---

## 三、工程实践类

### Q8: Skill 和脚本两种模式怎么选？

取决于使用场景：
- **Skill 模式**适合开发阶段：在 Claude Code 会话内执行，能看到每一步的分析过程，遇到不确定的修复方案会向你确认，可以随时干预。适合开发者坐在电脑前主动排查
- **脚本模式**适合无人值守：通过 `claude --print` 非交互运行，可以集成到 cron 定时任务或 webhook 回调中，适合下班后挂着跑或者 CI 流水线后置任务

两者逻辑完全一致，区别只是执行环境和交互方式。

### Q9: 为什么用轮询而不用 Webhook？

方案设计阶段对比过三种方案：轮询、Webhook + 内网穿透、CI 内直接调用。选择轮询因为：
1. **零外部依赖**：只需要 `gh` CLI 和 `claude` CLI，不需要搭建额外服务、配置 ngrok/cloudflared
2. **延迟可接受**：CI/CD 本身就要跑几分钟，30 秒的轮询延迟占比很小
3. **稳定性高**：不依赖网络穿透的稳定性，不会因为 ngrok 断连导致丢失通知

如果后续场景需要实时触发（比如多项目统一监控），可以升级到 Webhook 方案。

### Q10: 这个系统的边界在哪里？什么问题修不了？

核心边界是**只能修改代码仓库里的文件**。以下问题超出系统能力：
- 集群层面的基础设施问题（节点宕机、网络策略、存储卷异常）
- 需要修改 GitHub Secrets 的配置问题（数据库密码错误、ACR 认证过期）
- 第三方依赖服务不可用（数据库挂了、下游 API 不通）
- 需要人工审批的变更（生产环境发布、数据库 schema 迁移）

系统设计上通过最大重试次数兜底，修不了的问题 3 轮后会输出摘要建议人工介入，不会无限循环。

### Q11: auto-fix 是如何访问 ACK 集群信息的？本地需要安装 K8s 吗？

不需要安装 K8s，只需要安装两个 CLI 工具：

- **kubectl**：K8s 命令行客户端，只是一个远程连接工具，本身不运行 K8s。类似于 `mysql` 客户端不需要安装 MySQL 服务端
- **helm**：K8s 包管理工具，用来查询 Helm release 状态

然后将阿里云 ACK 集群的 kubeconfig 保存到本地 `~/.kube/config`，`kubectl` 和 `helm` 就能通过 HTTPS 远程访问 ACK 集群的 API Server，获取 Pod 状态、日志、Events 等信息。所有操作都是远程调用，本地不需要运行任何 K8s 组件。

```
本地电脑                              阿里云
┌──────────────┐    HTTPS/443    ┌──────────────┐
│ kubectl      │ ──────────────→ │ ACK API      │
│ helm         │                 │ Server       │
│              │                 │              │
│ ~/.kube/     │                 │  Pod 状态     │
│   config     │                 │  容器日志     │
│  (认证凭证)   │                 │  Events      │
└──────────────┘                 └──────────────┘
```
