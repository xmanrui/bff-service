# Auto-Fix 面试高频问题及参考回答

## 一、系统设计类

### Q1: 为什么不直接在 GitHub Actions 里调 LLM 修复，要绕回本地？

GitHub Actions 运行环境是临时容器，workflow 结束就销毁了。在 CI 里调 LLM 有三个问题：
1. LLM 修复代码需要完整的项目上下文（读文件、跨文件分析），CI 环境虽然有代码但没有交互式分析能力
2. 部署阶段失败时需要用 kubectl 访问 ACK 集群拉日志，CI 环境的集群权限是受限的临时凭证，而本地有长期的 kubeconfig
3. 本地执行可以用 Claude Code Skill 的交互模式，开发者能实时观察分析过程并随时干预，CI 里只能黑盒运行

### Q2: 为什么要双层检测？一层不够吗？

不够。CI 成功只代表 `helm upgrade --install` 命令执行成功了，K8s 接受了这个部署请求，但 Pod 可能根本跑不起来。实际生产中大量故障发生在运行时：CrashLoopBackOff、OOMKilled、探针失败、环境变量缺失等，这些在 CI 视角全是 success。不加第二层检测，这类故障就成了盲区。

### Q3: 为什么部署阶段失败要同时看 CI 日志和集群日志？

因为部署阶段的根因分布在两个地方。比如 `helm upgrade --wait --timeout 300s` 超时了，CI 日志只能看到 "timed out waiting for the condition"，但超时的原因是什么——是 Pod CrashLoopBackOff、探针失败、还是镜像拉取失败——这些信息只在集群的 Pod Events 和容器日志里。只看 CI 日志会导致 LLM 无法定位根因，只看集群日志又可能遗漏 Helm 模板渲染错误这类 CI 层面的问题。

### Q4: 二次稳定性检查解决什么问题？

解决"假健康"问题。有些应用启动后能正常运行几秒甚至几十秒，之后因为内存泄漏触发 OOMKilled，或者首次请求触发未捕获异常而崩溃。如果只检查一次，恰好在存活的那几秒查到了 Running 状态，就会误判为部署成功。间隔 30 秒再查一次，能捕获这种启动即崩溃的场景。

---

## 二、LLM / AI 相关

### Q5: LLM 修复错了怎么办？

有三层防护：
1. **重试上限**：最多 3 轮，防止无限循环消耗资源和 API 额度
2. **每轮独立分析**：每轮都重新拉取最新日志分析，不沿用上一轮的假设，所以第一轮修错了第二轮有机会纠正
3. **交互模式兜底**：Skill 模式下开发者能看到 Claude 的分析过程和修改内容，发现方向不对可以随时干预。超过 3 轮还没修好，输出所有尝试的摘要，由人工接手

另外这个系统定位是开发/测试环境的效率工具，不是生产环境的自动运维。生产环境应该走正规的发布流程和审批。

### Q6: Prompt 是怎么设计的？为什么要分三种？

不同场景的错误类型完全不同，用统一的 prompt 会导致 LLM 分析方向发散。分三种 prompt 的目的是**收窄分析范围**：
- **build prompt**：引导关注 Dockerfile、依赖、ACR 认证，不提集群相关内容
- **deploy prompt**：明确告知有两部分信息，引导综合分析，列举 Helm 模板、探针超时等典型场景
- **runtime prompt**：明确告知 CI 成功，引导关注运行时问题，列举 OOMKilled、环境变量缺失等场景

本质上是用 prompt 模拟了一个有经验的 SRE 的排查思路——先定位故障层，再在对应层内深入分析。

### Q7: 6 维诊断信息为什么要这么多？能不能只看 Pod 日志？

不行，不同故障的根因分布在不同维度：

| 故障 | 根因所在维度 |
|---|---|
| 代码运行时报错 | 容器日志 (`kubectl logs`) |
| 启动后立刻崩溃 | 上次崩溃日志 (`kubectl logs --previous`) |
| OOMKilled | Pod Events (`kubectl describe pod`) |
| 镜像拉取失败 | 集群 Events (`kubectl get events`) |
| 节点资源不足调度失败 | Pod 描述 (`kubectl describe pod`) |
| Helm values 配置错误 | Helm 状态 (`helm status`) |

只看容器日志能覆盖的故障不到一半。6 维信息是为了让 LLM 有足够的上下文做准确判断，减少因信息不全导致的误诊。

---

## 三、工程实践类

### Q8: Skill 和脚本两种模式怎么选？

取决于使用场景：
- **Skill 模式**适合开发阶段：在 Claude Code 会话内执行，能看到每一步的分析过程，遇到不确定的修复方案会向你确认，可以随时干预。适合开发者坐在电脑前主动排查
- **脚本模式**适合无人值守：通过 `claude --print` 非交互运行，可以集成到 cron 定时任务或 webhook 回调中，适合下班后挂着跑或者 CI 流水线后置任务

两者逻辑完全一致，区别只是执行环境和交互方式。

### Q9: 为什么用轮询而不用 Webhook？

方案设计阶段对比过三种方案：轮询、Webhook + 内网穿透、CI 内直接调用。选择轮询因为：
1. **零外部依赖**：只需要 `gh` CLI 和 `claude` CLI，不需要搭建额外服务、配置 ngrok/cloudflared
2. **延迟可接受**：CI/CD 本身就要跑几分钟，30 秒的轮询延迟占比很小
3. **稳定性高**：不依赖网络穿透的稳定性，不会因为 ngrok 断连导致丢失通知

如果后续场景需要实时触发（比如多项目统一监控），可以升级到 Webhook 方案。

### Q10: 这个系统的边界在哪里？什么问题修不了？

核心边界是**只能修改代码仓库里的文件**。以下问题超出系统能力：
- 集群层面的基础设施问题（节点宕机、网络策略、存储卷异常）
- 需要修改 GitHub Secrets 的配置问题（数据库密码错误、ACR 认证过期）
- 第三方依赖服务不可用（数据库挂了、下游 API 不通）
- 需要人工审批的变更（生产环境发布、数据库 schema 迁移）

系统设计上通过最大重试次数兜底，修不了的问题 3 轮后会输出摘要建议人工介入，不会无限循环。

### Q11: auto-fix 是如何访问 ACK 集群信息的？本地需要安装 K8s 吗？

不需要安装 K8s，只需要安装两个 CLI 工具：

- **kubectl**：K8s 命令行客户端，只是一个远程连接工具，本身不运行 K8s。类似于 `mysql` 客户端不需要安装 MySQL 服务端
- **helm**：K8s 包管理工具，用来查询 Helm release 状态

然后将阿里云 ACK 集群的 kubeconfig 保存到本地 `~/.kube/config`，`kubectl` 和 `helm` 就能通过 HTTPS 远程访问 ACK 集群的 API Server，获取 Pod 状态、日志、Events 等信息。所有操作都是远程调用，本地不需要运行任何 K8s 组件。

```
本地电脑                              阿里云
┌──────────────┐    HTTPS/443    ┌──────────────┐
│ kubectl      │ ──────────────→ │ ACK API      │
│ helm         │                 │ Server       │
│              │                 │              │
│ ~/.kube/     │                 │  Pod 状态     │
│   config     │                 │  容器日志     │
│  (认证凭证)   │                 │  Events      │
└──────────────┘                 └──────────────┘
```

### Q12: auto-fix 是如何访问 GitHub Actions 信息的？

通过 **GitHub CLI (`gh`)** 远程调用 GitHub API。`gh` 在登录后（`gh auth login`）会保存一个 OAuth token 到本地 keyring，之后所有命令都通过这个 token 认证访问 GitHub API。

auto-fix 中用到的 3 个 `gh` 命令：

```bash
# 1. 查询最新 workflow 运行状态
gh run list --workflow=deploy.yaml --branch=main --limit=1 --json databaseId,status,conclusion

# 2. 判断哪个 job 失败（build 还是 deploy）
gh run view <run_id> --json jobs

# 3. 拉取失败步骤的日志
gh run view <run_id> --log-failed
```

和 kubectl 访问 ACK 集群的模式一样——都是本地 CLI 工具通过认证凭证远程访问云端 API，本地不需要运行任何 GitHub 服务。

```
本地电脑                              GitHub
┌──────────────┐    HTTPS/443    ┌──────────────────┐
│ gh CLI       │ ──────────────→ │ GitHub API       │
│              │                 │                  │
│ OAuth token  │                 │  workflow 状态    │
│ (keyring)    │                 │  job 结论        │
│              │                 │  失败步骤日志     │
└──────────────┘                 └──────────────────┘
```

---

## 四、安全与成本

### Q13: 自动提交代码到 main 分支，安全风险怎么控制？

三个层面：
1. **环境隔离**：这个系统定位在开发/测试环境，生产环境走正规的 PR 审批流程，不会接入 auto-fix
2. **变更可审计**：每次修复都是独立的 git commit，有完整的提交记录和 diff，事后可以 review 和 revert
3. **爆炸半径控制**：最多 3 轮重试，每轮只修改必要的文件，不会大范围改动代码

如果要进一步加固，可以改为自动创建 PR 而不是直接 push 到 main，由人工 review 后合并。

### Q14: LLM 调用的成本怎么样？如何控制 token 消耗？

三个控制点：
1. **日志截取**：CI 日志 `tail -200`，集群日志 `tail -300`，Pod 日志 `--tail=80`，避免把完整日志塞给 LLM
2. **精准采集**：`gh run view --log-failed` 只拉失败步骤的日志，不拉成功步骤；kubectl 只查目标 Pod，不查全量
3. **重试上限**：最多 3 轮，每轮一次 LLM 调用，成本封顶可预估

一次完整的修复循环，token 消耗大概在日志输入 + 项目代码上下文 + 修复输出，和开发者手动用 Claude 分析一次问题的消耗差不多。

---

## 五、并发与扩展性

### Q15: 如果多人同时 push 代码触发了多个 workflow，auto-fix 会不会乱？

当前设计通过 `gh run list --limit=1` 只取最新一次 workflow run，所以始终跟踪最新的那次。如果 auto-fix 正在等待的时候有人又 push 了新代码，它会在下一轮轮询时切换到最新的 run。

这在单人开发场景下没问题。如果多人协作需要增强，可以在脚本启动时记录当前 commit SHA，轮询时校验 run 对应的 commit 是否匹配，避免跟踪错误的 workflow。

### Q16: 如果需要支持多个微服务，怎么扩展？

当前脚本中的 `HELM_RELEASE`、`K8S_NAMESPACE`、`WORKFLOW_FILE` 都是变量，支持多服务的方式：
1. **参数化**：把服务名作为参数传入 `./scripts/auto-fix.sh bff-service`，脚本内部根据参数设置对应的变量
2. **配置文件**：维护一个服务清单，循环遍历每个服务执行 auto-fix
3. **独立运行**：每个服务仓库放自己的 auto-fix，各自独立运行

不建议搞一个中心化的 auto-fix 管所有服务，保持每个服务自治更简单可靠。

---

## 六、可观测性与效果度量

### Q17: 你怎么衡量 auto-fix 的效果？有什么指标？

几个关键指标：
- **首次修复成功率**：第一轮就修好的比例，反映 prompt 设计和诊断信息的质量
- **平均修复轮次**：越少越好，理想是 1 轮
- **平均故障恢复时间（MTTR）**：对比人工排查的 MTTR，量化提效
- **超限退出率**：3 轮后仍失败需要人工介入的比例，反映系统能力边界

可以在脚本中加日志上报，统计这些指标。

### Q18: auto-fix 本身出 bug 了怎么排查？

脚本中每个关键步骤都有 `log()` 输出带时间戳的日志，能看到完整的执行轨迹：哪一步失败、拉到了什么日志、走了哪个分支、Claude 返回了什么。

Skill 模式下更直观，整个过程在 Claude Code 会话中可见，每一步的命令执行和输出都能直接看到。

---

## 七、与现有方案对比

### Q19: 为什么不用现有的 K8s 自愈能力（如 restartPolicy、HPA），还需要 auto-fix？

不是同一层面的事情。K8s 自愈能力解决的是**基础设施层的自愈**——Pod 崩溃了重启、流量大了扩容，但它不能修改代码。如果代码本身有 bug，K8s 重启一万次还是会崩溃。

auto-fix 解决的是**代码层的自愈**——分析为什么崩溃、修改源码、重新构建部署。两者是互补关系，不是替代关系。

### Q20: 运行一次 auto-fix 大概消耗多少 token？成本是多少？

单轮修复大约消耗 **5 万 token**，3 轮最坏约 **15 万 token**。

按 API 定价，单轮成本 Sonnet 约 **¥1.5**，Opus 约 **¥7**。3 轮最坏 Sonnet 约 **¥4.5**，Opus 约 **¥21**。

人工排查一次部署故障通常需要 15-30 分钟，折合 **¥37-75**。auto-fix 的成本大约是人工的 **1/10 到 1/50**。

如果用 Claude Code 订阅（固定月费），则不按 token 计费，成本更低。
